{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T07:26:02.796568Z",
     "start_time": "2024-09-16T07:25:58.386903Z"
    }
   },
   "source": [
    "import os.path\n",
    "\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import Language\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "\n",
    "repository_root = \"/Users/raynor/workspace/xxx/\"\n",
    "\n",
    "fitpetmall_backend_documents = []\n",
    "\n",
    "for path in [\"skeds\", ]:\n",
    "    loader = GenericLoader.from_filesystem(\n",
    "        os.path.join(repository_root, path),\n",
    "        glob=\"**/*\",\n",
    "        suffixes=[\".py\"],\n",
    "        parser=LanguageParser(language=Language.PYTHON.value, parser_threshold=30),\n",
    "    )\n",
    "    fitpetmall_backend_documents.extend(loader.load())\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings,\n",
    "    LocalFileStore(\"./.store/\"),\n",
    "    namespace=embeddings.model,\n",
    ")\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    fitpetmall_backend_documents,\n",
    "    cached_embeddings,\n",
    "    persist_directory=\"./.vector/\",\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:62: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:62: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:62: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:102: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:102: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:102: SyntaxWarning: invalid escape sequence '\\d'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T07:29:30.989303Z",
     "start_time": "2024-09-16T07:29:30.875642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})\n",
    "bm25_retriever = BM25Retriever.from_documents(fitpetmall_backend_documents)\n",
    "bm25_retriever.k = 10\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever, bm25_retriever],\n",
    "    weights=[0.4, 0.6],\n",
    "    search_type=\"mmr\",\n",
    ")"
   ],
   "id": "2272cdc5e8b1fbe9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T07:32:38.404741Z",
     "start_time": "2024-09-16T07:32:38.199952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "당신은 핏펫몰 백엔드 개발자 입니다. 당신의 임무는 주어진 질문에 대해여 최대한 주어진 코드를 활용하여 답변하는 것입니다.\n",
    "최대한 자세하게 답변하고, 주어진 코드로 답을 찾을수 없는 경우 `정보 부족으로 답변이 불가능합니다`로 답변 해주세요. \n",
    "답변은 출처(source) 코드를 반드시 표기해주세요.\n",
    "\n",
    "# 참고코드:\n",
    "{context}\n",
    "\n",
    "# 질문:\n",
    "{question}\n",
    "\n",
    "출처:\n",
    "- source1\n",
    "- source2\n",
    "- ...\n",
    "\"\"\")\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temparature=0)\n",
    "chain = {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "\n",
    "for token in chain.stream({\"context\": \"\", \"question\": \"주문 취소 로직에 대해서 알려줘\"}):\n",
    "    print(token, end=\"\", flush=True)"
   ],
   "id": "ba72811526071e8a",
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "invalid input type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResponseError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatOllama(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllama3.1\u001B[39m\u001B[38;5;124m\"\u001B[39m, temparature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     19\u001B[0m chain \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m\"\u001B[39m: ensemble_retriever, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m: RunnablePassthrough()} \u001B[38;5;241m|\u001B[39m prompt \u001B[38;5;241m|\u001B[39m llm \u001B[38;5;241m|\u001B[39m StrOutputParser()\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mquestion\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m주문 취소 로직에 대해서 알려줘\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflush\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3396\u001B[0m, in \u001B[0;36mRunnableSequence.stream\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3390\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m   3391\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3392\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   3393\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3394\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3395\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3396\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28miter\u001B[39m([\u001B[38;5;28minput\u001B[39m]), config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3383\u001B[0m, in \u001B[0;36mRunnableSequence.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   3378\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3379\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   3380\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3381\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3382\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3383\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m   3384\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   3385\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform,\n\u001B[1;32m   3386\u001B[0m         patch_config(config, run_name\u001B[38;5;241m=\u001B[39m(config \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m   3387\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3388\u001B[0m     )\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2186\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2184\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2185\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2186\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2187\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2188\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3346\u001B[0m, in \u001B[0;36mRunnableSequence._transform\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   3343\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3344\u001B[0m         final_pipeline \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39mtransform(final_pipeline, config)\n\u001B[0;32m-> 3346\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m final_pipeline\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/output_parsers/transform.py:65\u001B[0m, in \u001B[0;36mBaseTransformOutputParser.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Union[\u001B[38;5;28mstr\u001B[39m, BaseMessage]],\n\u001B[1;32m     52\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m     54\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T]:\n\u001B[1;32m     55\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Transform the input into the output format.\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;124;03m        The transformed output.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m     66\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform, config, run_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparser\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     67\u001B[0m     )\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2150\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2148\u001B[0m input_for_tracing, input_for_transform \u001B[38;5;241m=\u001B[39m tee(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m   2149\u001B[0m \u001B[38;5;66;03m# Start the input iterator to ensure the input Runnable starts before this one\u001B[39;00m\n\u001B[0;32m-> 2150\u001B[0m final_input: Optional[Input] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_for_tracing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   2151\u001B[0m final_input_supported \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2152\u001B[0m final_output: Optional[Output] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1402\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1399\u001B[0m final: Input\n\u001B[1;32m   1400\u001B[0m got_first_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1402\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1403\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001B[39;49;00m\n\u001B[1;32m   1404\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# then call stream.\u001B[39;49;00m\n\u001B[1;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001B[39;49;00m\n\u001B[1;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# the `+` operator.\u001B[39;49;00m\n\u001B[1;32m   1407\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001B[39;49;00m\n\u001B[1;32m   1408\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# only operate on the last chunk,\u001B[39;49;00m\n\u001B[1;32m   1409\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001B[39;49;00m\n\u001B[1;32m   1410\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgot_first_val\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfinal\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1402\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1399\u001B[0m final: Input\n\u001B[1;32m   1400\u001B[0m got_first_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1402\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1403\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001B[39;49;00m\n\u001B[1;32m   1404\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# then call stream.\u001B[39;49;00m\n\u001B[1;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001B[39;49;00m\n\u001B[1;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# the `+` operator.\u001B[39;49;00m\n\u001B[1;32m   1407\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001B[39;49;00m\n\u001B[1;32m   1408\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# only operate on the last chunk,\u001B[39;49;00m\n\u001B[1;32m   1409\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001B[39;49;00m\n\u001B[1;32m   1410\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgot_first_val\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfinal\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3833\u001B[0m, in \u001B[0;36mRunnableParallel.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3827\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   3828\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3829\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   3830\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3831\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   3832\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Dict[\u001B[38;5;28mstr\u001B[39m, Any]]:\n\u001B[0;32m-> 3833\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m   3834\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m   3835\u001B[0m     )\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2186\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2184\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2185\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2186\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2187\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2188\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3818\u001B[0m, in \u001B[0;36mRunnableParallel._transform\u001B[0;34m(self, input, run_manager, config)\u001B[0m\n\u001B[1;32m   3816\u001B[0m (step_name, generator) \u001B[38;5;241m=\u001B[39m futures\u001B[38;5;241m.\u001B[39mpop(future)\n\u001B[1;32m   3817\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3818\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m AddableDict({step_name: \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m})\n\u001B[1;32m   3819\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   3820\u001B[0m     futures[executor\u001B[38;5;241m.\u001B[39msubmit(\u001B[38;5;28mnext\u001B[39m, generator)] \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   3821\u001B[0m         step_name,\n\u001B[1;32m   3822\u001B[0m         generator,\n\u001B[1;32m   3823\u001B[0m     )\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1420\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1417\u001B[0m             final \u001B[38;5;241m=\u001B[39m ichunk\n\u001B[1;32m   1419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m got_first_val:\n\u001B[0;32m-> 1420\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(final, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:986\u001B[0m, in \u001B[0;36mRunnable.stream\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    968\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m    969\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    970\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m    971\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    972\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m    973\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[1;32m    974\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;124;03m    Default implementation of stream, which calls invoke.\u001B[39;00m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    984\u001B[0m \u001B[38;5;124;03m        The output of the Runnable.\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 986\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py:118\u001B[0m, in \u001B[0;36mEnsembleRetriever.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    117\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_retriever_error(e)\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    120\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_retriever_end(\n\u001B[1;32m    121\u001B[0m         result,\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    123\u001B[0m     )\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py:115\u001B[0m, in \u001B[0;36mEnsembleRetriever.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    108\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_retriever_start(\n\u001B[1;32m    109\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m    111\u001B[0m     name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    113\u001B[0m )\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 115\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrank_fusion\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    117\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_retriever_error(e)\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py:223\u001B[0m, in \u001B[0;36mEnsembleRetriever.rank_fusion\u001B[0;34m(self, query, run_manager, config)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    211\u001B[0m \u001B[38;5;124;03mRetrieve the results of the retrievers and use rank_fusion_func to get\u001B[39;00m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;124;03mthe final result.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03m    A list of reranked documents.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;66;03m# Get the results of all retrievers.\u001B[39;00m\n\u001B[1;32m    222\u001B[0m retriever_docs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m--> 223\u001B[0m     \u001B[43mretriever\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpatch_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mretriever_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, retriever \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretrievers)\n\u001B[1;32m    230\u001B[0m ]\n\u001B[1;32m    232\u001B[0m \u001B[38;5;66;03m# Enforce that retrieved docs are Documents for each list in retriever_docs\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(retriever_docs)):\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py:254\u001B[0m, in \u001B[0;36mBaseRetriever.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    253\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_retriever_error(e)\n\u001B[0;32m--> 254\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    256\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_retriever_end(\n\u001B[1;32m    257\u001B[0m         result,\n\u001B[1;32m    258\u001B[0m     )\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py:247\u001B[0m, in \u001B[0;36mBaseRetriever.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    245\u001B[0m _kwargs \u001B[38;5;241m=\u001B[39m kwargs \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expects_other_args \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new_arg_supported:\n\u001B[0;32m--> 247\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_relevant_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_kwargs\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_relevant_documents(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs)\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:1054\u001B[0m, in \u001B[0;36mVectorStoreRetriever._get_relevant_documents\u001B[0;34m(self, query, run_manager)\u001B[0m\n\u001B[1;32m   1052\u001B[0m     docs \u001B[38;5;241m=\u001B[39m [doc \u001B[38;5;28;01mfor\u001B[39;00m doc, _ \u001B[38;5;129;01min\u001B[39;00m docs_and_similarities]\n\u001B[1;32m   1053\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmr\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1054\u001B[0m     docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvectorstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_marginal_relevance_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1055\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_kwargs\u001B[49m\n\u001B[1;32m   1056\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1058\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msearch_type of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not allowed.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:649\u001B[0m, in \u001B[0;36mChroma.max_marginal_relevance_search\u001B[0;34m(self, query, k, fetch_k, lambda_mult, filter, where_document, **kwargs)\u001B[0m\n\u001B[1;32m    644\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embedding_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    645\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    646\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor MMR search, you must specify an embedding function on\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreation.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    647\u001B[0m     )\n\u001B[0;32m--> 649\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embedding_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    650\u001B[0m docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_marginal_relevance_search_by_vector(\n\u001B[1;32m    651\u001B[0m     embedding,\n\u001B[1;32m    652\u001B[0m     k,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    656\u001B[0m     where_document\u001B[38;5;241m=\u001B[39mwhere_document,\n\u001B[1;32m    657\u001B[0m )\n\u001B[1;32m    658\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m docs\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain/embeddings/cache.py:194\u001B[0m, in \u001B[0;36mCacheBackedEmbeddings.embed_query\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Embed query text.\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \n\u001B[1;32m    184\u001B[0m \u001B[38;5;124;03mBy default, this method does not cache queries. To enable caching, set the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;124;03m    The embedding for the given text.\u001B[39;00m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquery_embedding_store:\n\u001B[0;32m--> 194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munderlying_embeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m (cached,) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquery_embedding_store\u001B[38;5;241m.\u001B[39mmget([text])\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_ollama/embeddings.py:160\u001B[0m, in \u001B[0;36mOllamaEmbeddings.embed_query\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membed_query\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[1;32m    159\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Embed query text.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/langchain_ollama/embeddings.py:155\u001B[0m, in \u001B[0;36mOllamaEmbeddings.embed_documents\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membed_documents\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts: List[\u001B[38;5;28mstr\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[List[\u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[1;32m    154\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Embed search docs.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 155\u001B[0m     embedded_docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m embedded_docs\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/ollama/_client.py:262\u001B[0m, in \u001B[0;36mClient.embed\u001B[0;34m(self, model, input, truncate, options, keep_alive)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model:\n\u001B[1;32m    260\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m RequestError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmust provide a model\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPOST\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/api/embed\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m  \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtruncate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moptions\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mkeep_alive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m  \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[0;32m~/workspace/ai-demos/.venv/lib/python3.12/site-packages/ollama/_client.py:75\u001B[0m, in \u001B[0;36mClient._request\u001B[0;34m(self, method, url, **kwargs)\u001B[0m\n\u001B[1;32m     73\u001B[0m   response\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mHTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m---> 75\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m ResponseError(e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mtext, e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mstatus_code) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[0;31mResponseError\u001B[0m: invalid input type"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa1a6e2a27d7a55c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
